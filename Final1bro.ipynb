{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZn56AigPVjX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error, r2_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ================================================================\n",
        "# 1. USER CONFIGURATION\n",
        "# ================================================================\n",
        "# Choose: \"Classification\" (Categories) or \"Regression\" (Numbers)\n",
        "TASK_TYPE = \"Classification\"\n",
        "\n",
        "# File Paths\n",
        "TRAIN_PATH  = \"/kaggle/input/ai-201-b-mse-2-aiml-a/train.csv\"\n",
        "TEST_PATH   = \"/kaggle/input/ai-201-b-mse-2-aiml-a/test.csv\"\n",
        "SAMPLE_PATH = \"/kaggle/input/ai-201-b-mse-2-aiml-a/sample_submission.csv\"\n",
        "\n",
        "# Column Names\n",
        "TARGET_COL  = \"NObeyesdad\" # The column you want to predict\n",
        "ID_COL      = \"id\"          # The ID column to ignore\n",
        "\n",
        "# Unwanted columns to drop immediately (IDs, Names, etc.)\n",
        "# NOTE: Add 'CustomerId' or 'Surname' here if they exist in your data\n",
        "DROP_COLS   = [ID_COL, \"CustomerId\", \"Surname\", \"RowNumber\"]\n",
        "\n",
        "# ================================================================\n",
        "# 2. LOAD DATA & TEXT EDA\n",
        "# ================================================================\n",
        "print(\"--- LOADING DATA ---\")\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SAMPLE_PATH)\n",
        "\n",
        "# Save IDs for submission before dropping them\n",
        "test_ids = test[ID_COL] if ID_COL in test.columns else test.index\n",
        "\n",
        "# --- USER REQUESTED EDA STEPS ---\n",
        "print(\"\\n--- 1. DATA INFO ---\")\n",
        "print(train.info())\n",
        "\n",
        "print(\"\\n--- 2. FIRST 5 ROWS (RAW) ---\")\n",
        "print(train.head())\n",
        "\n",
        "print(f\"\\n--- 3. DROPPING UNWANTED COLUMNS: {DROP_COLS} ---\")\n",
        "# Dropping columns inplace as requested\n",
        "train.drop(columns=DROP_COLS, axis=1, inplace=True, errors='ignore')\n",
        "test.drop(columns=DROP_COLS, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "print(\"\\n--- 4. FIRST 5 ROWS (AFTER DROP) ---\")\n",
        "print(train.head())\n",
        "\n",
        "print(\"\\n--- 5. MISSING VALUES ---\")\n",
        "print(train.isnull().sum())\n",
        "\n",
        "print(\"\\n--- 6. DUPLICATES ---\")\n",
        "print(train.duplicated().sum())\n",
        "\n",
        "print(\"\\n--- 7. UNIQUE VALUES PER COLUMN ---\")\n",
        "print(train.nunique())\n",
        "\n",
        "# ================================================================\n",
        "# 3. VISUAL EDA (BOXPLOTS & HEATMAP ONLY)\n",
        "# ================================================================\n",
        "print(\"\\n--- GENERATING PLOTS ---\")\n",
        "\n",
        "# Separate numeric cols for plotting\n",
        "eda_num_cols = train.select_dtypes(include=['number']).columns\n",
        "\n",
        "if len(eda_num_cols) > 0:\n",
        "    # PLOT 1: Boxplots (Outlier Detection)\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    # Normalize data for visualization so all boxplots fit on one scale\n",
        "    sns.boxplot(data=(train[eda_num_cols] - train[eda_num_cols].mean()) / train[eda_num_cols].std())\n",
        "    plt.title(\"Outlier Detection (Normalized Boxplots)\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()\n",
        "\n",
        "    # PLOT 2: Correlation Heatmap\n",
        "    if len(eda_num_cols) > 1:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(train[eda_num_cols].corr(), annot=True, fmt=\".1f\", cmap='coolwarm', linewidths=0.5)\n",
        "        plt.title(\"Feature Correlation Matrix\")\n",
        "        plt.show()\n",
        "\n",
        "# ================================================================\n",
        "# 4. PREPROCESSING & SPLIT\n",
        "# ================================================================\n",
        "print(\"\\n--- PREPROCESSING ---\")\n",
        "\n",
        "# Separate X and y\n",
        "X = train.drop(columns=[TARGET_COL])\n",
        "y = train[TARGET_COL]\n",
        "\n",
        "# Identify columns automatically\n",
        "num_cols = X.select_dtypes(include=['int64','float64']).columns\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# --- 4.1 Handle Null Values (Median/Mode) ---\n",
        "# Replacing nulls BEFORE capping outliers to ensure data consistency\n",
        "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
        "test[num_cols] = test[num_cols].fillna(test[num_cols].median())\n",
        "\n",
        "if len(cat_cols) > 0:\n",
        "    X[cat_cols] = X[cat_cols].fillna(X[cat_cols].mode().iloc[0])\n",
        "    test[cat_cols] = test[cat_cols].fillna(test[cat_cols].mode().iloc[0])\n",
        "\n",
        "# --- 4.2 Robust Outlier Capping (Category-wise) ---\n",
        "def cap_outliers_categorywise(df, cat_col, num_cols):\n",
        "    df = df.copy()\n",
        "    for col in num_cols:\n",
        "        if df[cat_col].nunique() < 50: # Only apply if category count is reasonable\n",
        "            Q1 = df.groupby(cat_col)[col].transform(lambda x: x.quantile(0.25))\n",
        "            Q3 = df.groupby(cat_col)[col].transform(lambda x: x.quantile(0.75))\n",
        "            IQR = Q3 - Q1\n",
        "            df[col] = df[col].clip(Q1 - 1.5 * IQR, Q3 + 1.5 * IQR)\n",
        "    return df\n",
        "\n",
        "print(\"Capping Outliers (using robust IQR method)...\")\n",
        "for c in cat_cols:\n",
        "    X = cap_outliers_categorywise(X, c, num_cols)\n",
        "    test = cap_outliers_categorywise(test, c, num_cols)\n",
        "\n",
        "# --- Target Encoding ---\n",
        "le = LabelEncoder()\n",
        "if TASK_TYPE == \"Classification\":\n",
        "    y_encoded = le.fit_transform(y)\n",
        "    print(f\"Target Encoded. Mapping: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
        "else:\n",
        "    y_encoded = y\n",
        "\n",
        "# --- Pipeline Setup ---\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "        (\"num\", \"passthrough\", num_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- Model Selection ---\n",
        "if TASK_TYPE == \"Classification\":\n",
        "    model = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "else:\n",
        "    model = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"clf\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "\n",
        "# ================================================================\n",
        "# 5. TRAINING & EVALUATION\n",
        "# ================================================================\n",
        "print(\"\\n--- TRAINING MODEL ---\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_val = model.predict(X_val)\n",
        "\n",
        "print(f\"\\n===== {TASK_TYPE.upper()} PERFORMANCE =====\")\n",
        "if TASK_TYPE == \"Classification\":\n",
        "    print(\"Accuracy:\", accuracy_score(y_val, y_pred_val))\n",
        "    print(\"F1 Score:\", f1_score(y_val, y_pred_val, average='macro'))\n",
        "else:\n",
        "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_val, y_pred_val)))\n",
        "    print(\"R2 Score:\", r2_score(y_val, y_pred_val))\n",
        "\n",
        "# ================================================================\n",
        "# 6. FINAL PREDICTION & SUBMISSION (SMART LOGIC)\n",
        "# ================================================================\n",
        "print(\"\\n--- GENERATING SUBMISSION ---\")\n",
        "\n",
        "# 1. Retrain on full data\n",
        "model.fit(X, y_encoded)\n",
        "\n",
        "# 2. Setup Submission DataFrame using IDs from TEST file (Safe Method)\n",
        "submission = pd.DataFrame()\n",
        "submission[ID_COL] = test_ids\n",
        "\n",
        "# 3. Identify sample submission format\n",
        "sample_cols = [c for c in sample_sub.columns if c != ID_COL]\n",
        "\n",
        "if len(sample_cols) == 1:\n",
        "    # --- SCENARIO 1: Simple Prediction ---\n",
        "    print(f\"Detected Single Target: {sample_cols[0]}\")\n",
        "    preds = model.predict(test)\n",
        "\n",
        "    if TASK_TYPE == \"Classification\":\n",
        "        submission[sample_cols[0]] = le.inverse_transform(preds) # Words\n",
        "    else:\n",
        "        submission[sample_cols[0]] = preds # Numbers\n",
        "\n",
        "else:\n",
        "    # --- SCENARIO 2: Probabilities ---\n",
        "    print(f\"Detected Multi-Class Probabilities ({len(sample_cols)} cols)\")\n",
        "    probs = model.predict_proba(test)\n",
        "\n",
        "    for i, class_name in enumerate(le.classes_):\n",
        "        found_col = [col for col in sample_cols if str(class_name) in col]\n",
        "        if found_col:\n",
        "            submission[found_col[0]] = probs[:, i]\n",
        "\n",
        "# 4. Save\n",
        "submission.to_csv(\"submission_final.csv\", index=False)\n",
        "print(\"\\nsubmission_final.csv CREATED!\")\n",
        "print(submission.head())"
      ]
    }
  ]
}